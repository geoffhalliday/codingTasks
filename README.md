# Task 21 - Supervised Learning - Random Forests

## Summary of tasks:
"Create a bagged, random forest, and boosted tree for the Titanic data set in the same way that you created a regular classification tree.
From the random forest model, determine which of the features is the one that contributes the most to predicting whether a passenger survives or not.
Pick one of these methods, and tune the parameters n_estimators and max_depth.
Report the accuracy of all models and report which model performed the best, including the values for n_estimators and max_depth that the best model had."

## Requirements:
Jupyter notebook

Python (Including: pandas; sklearn.model_selection; sklearn.tree; sklearn; matplotlib.pyplot; sklearn.metrics; sklearn.ensemble)

titanic.csv file

## Usage
Run the file in suitable environment (e.g. VS Code), using Python 3.12.2

The first section (Task 20) generates decision trees and finds optimal parameters
![image](https://github.com/geoffhalliday/codingTasks/assets/163735161/e0a1f91c-19a6-4d6c-a953-886485e92878)

The second section (Task 21)creates random forest models and practices tuning parameters
![image](https://github.com/geoffhalliday/codingTasks/assets/163735161/e2112701-13aa-4d85-9da9-eb5a3357a386)

## Credits
Geoff Haliday
